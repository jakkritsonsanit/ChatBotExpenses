{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Category (Decision Tree)\n",
    "##### Mr.Jakkrit Sonsanit\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pythainlp.corpus.common import thai_words\n",
    "from pythainlp.tokenize import dict_trie, word_tokenize\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>money</th>\n",
       "      <th>cate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>2019-11-21</td>\n",
       "      <td>กระเจี๊ยบ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>2019-11-21</td>\n",
       "      <td>นม</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>2019-11-21</td>\n",
       "      <td>ข้าวเย็น</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>2019-11-21</td>\n",
       "      <td>ขนม</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>2019-11-21</td>\n",
       "      <td>ชานม</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Food</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date       text  money  cate\n",
       "257  2019-11-21  กระเจี๊ยบ    5.0  Food\n",
       "258  2019-11-21         นม   10.0  Food\n",
       "259  2019-11-21   ข้าวเย็น   45.0  Food\n",
       "260  2019-11-21        ขนม   20.0  Food\n",
       "261  2019-11-21       ชานม   45.0  Food"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Expenses.csv\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['นม', 'ช็อคโกแลต', 'ข้าว', 'เที่ยง', 'น้ำ', 'กระเจี๊ยบ', 'ชา', 'ข้าวเย็น', 'ค่า', 'อินเตอร์เน็ต', 'ค่าโทรศัพท์', 'หมา', 'ล่า', 'ไอติม', 'ตัดผม', 'ซาลาเปา', 'ไส้กรอก', 'ดอย', 'คำ', 'ใบมีดโกน', 'ห้อง', 'Netflix', 'เงินเก็บ', 'ราเมง', 'นมเปรี้ยว', 'ขนมปัง', 'ขนม', 'arl', 'mrt', 'ซื้อ', 'กางเกง', 'ถั่ว', 'มาม่า', 'อิชิตัน', 'คาปูชิโน่', 'viu', 'บัวลอย', 'ค่ารถ', 'โกโก้', 'หนัง', 'เติม', 'เกม', 'ดู', 'โอ้', 'เด้ง', 'ป็อป', 'คอน', 'เหล้า', 'กระ', 'เพรา', 'หอมมะลิ', 'หอยลาย', 'ปุ้มปุ้ย', 'พริก', 'แกง', 'หมู', 'น้ำเปล่า', 'กระทะ', 'เสื้อ', 'กระเป๋า', 'อิเกีย', 'แท๊กซี่', 'ลูกชิ้น', 'มะละกอ', 'นวด', 'ติ๋ม', 'ซำ', 'ธูป', 'เทียน', 'ซักผ้า', ' ', 'spotify', 'สอง', 'แถว', '2', 'ก๋วยเตี๋ยว', 'ปลากระป๋อง', 'กับข้าว', 'มะตูม', 'หวาน', 'น้ำเต้าหู้', 'โอ', 'BTS', 'ตุ้มหู', 'ไข่ลวก', 'ทูน่า', 'ปลา', 'แอปเปิ้ล', 'ยำ', 'รถตู้', 'bts', 'อินเทอร์เน็ต', 'ชาบู', 'เสาวรส', 'เนื้อ', 'ย่าง', 'ครีมกันแดด', 'มะนาว', 'โซดา', 'ช็อกโกแลต', 'แชมพู', 'ครีม']\n"
     ]
    }
   ],
   "source": [
    "custom_dict = set(thai_words())\n",
    "word = ['ราเมง', 'อิเกีย', 'คาปูชิโน่', 'น้ำมัน','หอยลาย', 'ปุ้มปุ้ย']\n",
    "for i in word:\n",
    "    custom_dict.add(i)\n",
    "trie = dict_trie(dict_source=custom_dict)\n",
    "\n",
    "corpus = []\n",
    "for i in df.text:\n",
    "    for j in word_tokenize(i, engine='dict', custom_dict=trie):\n",
    "        if j not in corpus:\n",
    "            corpus.append(j)\n",
    "corpus\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Bag of Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOW = [list() for i in range(len(df.text))]\n",
    "l = 0\n",
    "count = 1\n",
    "for i in df.text:\n",
    "    tmp = word_tokenize(i, engine='dict', custom_dict=trie)\n",
    "    for j in corpus:\n",
    "\n",
    "        if j in tmp:\n",
    "\n",
    "            BOW[l].append(tmp.count(j))\n",
    "            tmp.remove(j)\n",
    "            \n",
    "        else:\n",
    "            BOW[l].append(0)\n",
    "        \n",
    "    if len(tmp) != 0:\n",
    "        BOW[l].append(len(tmp))\n",
    "    elif len(tmp) == 0:\n",
    "        BOW[l].append(0)\n",
    "    l += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytarget = df.cate\n",
    "xtrain = BOW\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X=xtrain,y=ytarget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation 5 fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jakkrit/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8982818066429926"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(dtree, xtrain, ytarget, cv=5, scoring=\"accuracy\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Bag of Word form Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "txt = ['ซื้อน้ำยาปรับผ้านุ่ม']\n",
    "BOW_t = [list() for i in range(len(txt))]\n",
    "l = 0\n",
    "for i in txt:\n",
    "    tmp = word_tokenize(i, engine='dict', custom_dict=trie)\n",
    "    for j in corpus:\n",
    "\n",
    "        if j in tmp:\n",
    "\n",
    "            BOW_t[l].append(tmp.count(j))\n",
    "            tmp.remove(j)\n",
    "        else:\n",
    "            BOW_t[l].append(0)\n",
    "        \n",
    "    if len(tmp) != 0:\n",
    "        BOW_t[l].append(len(tmp))\n",
    "    elif len(tmp) == 0:\n",
    "        BOW_t[l].append(0)\n",
    "    l += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Bag of word with corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_t = corpus.append('Other')\n",
    "# ch = pd.DataFrame({\n",
    "#     'train':corpus,\n",
    "#     'target':BOW_t[0]\n",
    "# })\n",
    "# ch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Category "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Shopping'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictiontree = dtree.predict(BOW_t)\n",
    "predictiontree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
